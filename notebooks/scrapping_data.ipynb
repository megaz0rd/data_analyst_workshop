{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "9626bb5c-160d-4158-9345-4a49443d815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import date\n",
    "\n",
    "today = date.today().strftime('%d_%m_%Y')\n",
    "\n",
    "def find_files(position: str) :\n",
    "    files = glob.glob(f'./../data/raw/{position}_*.html')\n",
    "    return files\n",
    "\n",
    "def read_file(path: str):\n",
    "    with open(path, 'r') as file:\n",
    "        soup = bs(file)\n",
    "        html = soup.find_all(class_=\"list-container ng-star-inserted\")\n",
    "        jobs = [container.find_all(class_=\"posting-list-item\") for container in html]\n",
    "    return jobs\n",
    "\n",
    "def parse_location(location):\n",
    "    location_dict = {}\n",
    "    if location is not None:\n",
    "        location = location.text.replace('\\n', \"\").strip().split(',')\n",
    "        if len(location) > 1:\n",
    "            location_dict['city'], location_dict['country'] = location[0], location[1].strip().split(' ')[0]\n",
    "    else:\n",
    "        location_dict['city'], location_dict['country'] = \"Zdalna\", \"N/A\"\n",
    "    return location_dict\n",
    "\n",
    "def parse_salary(salary):\n",
    "    salary_dict = {}\n",
    "    \n",
    "    regex = '\\d+\\s\\d+'\n",
    "    bounds = re.findall(regex, salary)\n",
    "    bounds = [int(b.replace(u'\\xa0', \"\")) for b in bounds]\n",
    "    \n",
    "    if bounds:\n",
    "        if len(bounds) == 2:\n",
    "            if bounds[0] < bounds[1]:\n",
    "                salary_dict['low'], salary_dict['high'] = bounds[0], bounds[1]\n",
    "            else:\n",
    "                salary_dict['low'], salary_dict['high'] = bounds[1], bounds[0]\n",
    "        elif len(bounds) == 1:\n",
    "            salary_dict['low'], salary_dict['high'] = bounds[0], bounds[0]\n",
    "    else:\n",
    "        salary_dict['low'], salary_dict['high'] = 'N/A', 'N/A'\n",
    "            \n",
    "    regex = '[a-zA-Z]+'\n",
    "    currency = re.findall(regex, salary)\n",
    "    if currency:\n",
    "        salary_dict['currency'] = currency[0]\n",
    "    else:\n",
    "        salary_dict['currency'] = \"N/A\"\n",
    "        \n",
    "    return salary_dict\n",
    "\n",
    "def parse_technology(technology):\n",
    "    if technology is not None:\n",
    "        return technology.text.strip()\n",
    "    else:\n",
    "        return \"N/A\"\n",
    "\n",
    "def generate_dictionaries(jobs, position):\n",
    "    job_offers = []\n",
    "    for job in jobs:\n",
    "        name = job.find(class_=\"posting-title__position\").text.strip()\n",
    "        company = job.find(class_='posting-title__company').text.strip()\n",
    "        salary = parse_salary(job.find(angularticscategory=\"engagement\").text)\n",
    "        location = parse_location(job.find('nfj-posting-item-city'))\n",
    "        technology = parse_technology(job.find('common-posting-item-tag'))\n",
    "        job_details = {\n",
    "            'name': name,\n",
    "            'company': company,\n",
    "            'technology': technology,\n",
    "            'job': position, \n",
    "            'location': location,\n",
    "            'salary': salary,\n",
    "        }\n",
    "        job_offers.append(job_details)\n",
    "    return job_offers\n",
    "\n",
    "def get_dataframe(job_offers, position):\n",
    "    return pd.json_normalize(job_offers)\n",
    "    \n",
    "def save_to_csv(df_list, position):\n",
    "    df = pd.concat(df_list)\n",
    "    df.to_csv(f'./../data/interim/{position}_{today}.csv', encoding='utf8', index=False)\n",
    "    print('Zapisano dane do plików .csv')\n",
    "    \n",
    "def parse_len(files):\n",
    "    if len(files) == 1:\n",
    "        return '1 plik'\n",
    "    elif 1 < len(files) < 5:\n",
    "        return f'{len(files)} pliki'\n",
    "    else:\n",
    "        return f\"{len(files)} plików\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "c4add11c-68ba-448f-a778-62a8872d7bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(position):\n",
    "    files = find_files(position)\n",
    "    \n",
    "    print(f\"Znaleziono {parse_len(files)} z ofertami pracy dla {' '.join(position.split('_'))}\")\n",
    "    df_list = []\n",
    "    jobs_count = 0\n",
    "\n",
    "    for file in files:\n",
    "        containers = read_file(file)\n",
    "        for jobs in containers:\n",
    "            job_offers = generate_dictionaries(jobs, position)\n",
    "            df = get_dataframe(job_offers, position)\n",
    "            df_list.append(df)\n",
    "            jobs_count += len(jobs)\n",
    "    print(f\"Pobrano {jobs_count} ogłoszeń\")\n",
    "    \n",
    "    save_to_csv(df_list, position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "365c322f-a737-429b-8cc8-9162bcbc046e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znaleziono 5 plików z ofertami pracy dla python developer\n",
      "Pobrano 100 ogłoszeń\n",
      "Zapisano dane do plików .csv\n"
     ]
    }
   ],
   "source": [
    "main('python_developer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837556c-6d65-4965-a2c6-7dbaae2f9084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
